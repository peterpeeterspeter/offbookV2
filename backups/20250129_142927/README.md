# AI Actor Practice Platform

A real-time platform for actors to practice their craft with AI-powered feedback and emotion analysis.

## Features

- ğŸ­ Real-time emotion analysis using DeepSeek
- ğŸ™ï¸ High-quality audio streaming with WebRTC (Daily.co)
- ğŸ“Š Live audio level visualization
- ğŸ’¬ Instant performance feedback
- ğŸŒ™ Dark/Light mode support
- ğŸ¯ Frame-based audio processing pipeline
- ğŸ”„ Real-time state management
- ğŸš€ Low-latency audio processing

## Tech Stack

- **Frontend**:
  - Next.js 14 with TypeScript
  - Tailwind CSS with shadcn/ui components
  - WebRTC integration via Daily.co
  - React Query for API state management

- **Backend**:
  - Pipecat for audio processing pipeline
  - FastAPI for REST endpoints
  - WebSocket support for real-time communication

- **AI Services**:
  - ElevenLabs for Text-to-Speech
  - DeepSeek for emotion analysis
  - Whisper for speech recognition
  - Custom CNN for emotion classification

## Project Structure

```
src/
â”œâ”€â”€ app/                    # Next.js app directory
â”‚   â”œâ”€â”€ practice/          # Practice session pages
â”‚   â”‚   â”œâ”€â”€ practice-room.tsx
â”‚   â”‚   â””â”€â”€ layout.tsx         # Root layout with providers
â”‚   â””â”€â”€ layout.tsx         # Root layout with providers
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ practice-session/  # Practice session components
â”‚   â”‚   â”œâ”€â”€ practice-room.tsx
â”‚   â”‚   â””â”€â”€ audio-level-indicator.tsx
â”‚   â””â”€â”€ ui/               # Reusable UI components
â”‚       â”œâ”€â”€ button.tsx
â”‚       â”œâ”€â”€ card.tsx
â”‚       â””â”€â”€ toast.tsx
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ hooks/            # Custom React hooks
â”‚   â”‚   â””â”€â”€ use-daily-call.ts
â”‚   â””â”€â”€ utils.ts          # Utility functions
â””â”€â”€ styles/
    â””â”€â”€ globals.css       # Global styles and Tailwind

backend/
â”œâ”€â”€ pipelines/           # Pipecat pipeline definitions
â”œâ”€â”€ services/           # AI service integrations
â”œâ”€â”€ models/            # Data models and schemas
â””â”€â”€ utils/             # Helper functions
```

## Getting Started

1. **Clone the repository**
```bash
git clone <repository-url>
cd ai-actor-practice
```

2. **Install dependencies**
```bash
npm install
```

3. **Set up environment variables**
Create a `.env.local` file:
```env
NEXT_PUBLIC_DAILY_ROOM_URL=your_daily_room_url
ELEVENLABS_API_KEY=your_elevenlabs_key
DEEPSEEK_API_KEY=your_deepseek_key
```

4. **Run the development server**
```bash
npm run dev
```

5. **Build for production**
```bash
npm run build
npm start
```

## Key Components

### PracticeRoom
The main component for practice sessions, handling:
- WebRTC audio streaming
- Real-time audio level monitoring
- Connection state management
- Error handling

### Audio Pipeline
Frame-based processing pipeline featuring:
- Voice activity detection
- Audio quality analysis
- Emotion analysis
- Performance feedback

### AI Integration
Multiple AI services working together:
- Real-time emotion analysis
- Speech-to-text conversion
- Performance scoring
- Feedback generation

## Contributing

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## License

This project is licensed under the MIT License - see the LICENSE file for details.

## Acknowledgments

- Daily.co for WebRTC infrastructure
- ElevenLabs for TTS capabilities
- DeepSeek for emotion analysis
- OpenAI for Whisper ASR 